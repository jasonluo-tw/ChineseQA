{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers.recurrent_test4 import *\n",
    "from model3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\", end='')\n",
    "#with open('../train_process_final.pkl', 'rb') as f:\n",
    "with open('../test_process_final.pkl', 'rb') as f:\n",
    "    datas = pickle.load(f)\n",
    "\n",
    "ids, all_context, test_context, ques, encode_context, encode_ques = datas\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model...\n",
      "Preparing model...__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Passage (InputLayer)            (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Question (InputLayer)           (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        multiple             12108300    Passage[0][0]                    \n",
      "                                                                 Question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_52 (Bidirectional (None, 20, 150)      169200      embedding_17[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_49 (Bidirectional (None, 300, 150)     169200      embedding_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_53 (Bidirectional (None, 20, 150)      101700      bidirectional_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_50 (Bidirectional (None, 300, 150)     101700      bidirectional_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_54 (Bidirectional (None, 20, 150)      101700      bidirectional_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "WQ_u (SharedWeightLayer)        (150, 75)            11250                                        \n",
      "__________________________________________________________________________________________________\n",
      "v (SharedWeightLayer)           (75, 1)              75                                           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_51 (Bidirectional (None, 300, 150)     101700      bidirectional_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "WP_u (SharedWeightLayer)        (150, 75)            11250                                        \n",
      "__________________________________________________________________________________________________\n",
      "WP_v (SharedWeightLayer)        (75, 75)             5625                                         \n",
      "__________________________________________________________________________________________________\n",
      "W_g1 (SharedWeightLayer)        (150, 150)           22500                                        \n",
      "__________________________________________________________________________________________________\n",
      "vv (SharedWeightLayer)          (300, 150)           45000                                        \n",
      "__________________________________________________________________________________________________\n",
      "rnn_41 (RNN)                    (None, 300, 75)      101700      bidirectional_51[0][0]           \n",
      "                                                                 WP_u[0][0]                       \n",
      "                                                                 bidirectional_54[0][0]           \n",
      "                                                                 WQ_u[0][0]                       \n",
      "                                                                 WP_v[0][0]                       \n",
      "                                                                 v[0][0]                          \n",
      "                                                                 W_g1[0][0]                       \n",
      "                                                                 vv[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "rnn_42 (RNN)                    (None, 300, 75)      101700      bidirectional_51[0][0]           \n",
      "                                                                 WP_u[0][0]                       \n",
      "                                                                 bidirectional_54[0][0]           \n",
      "                                                                 WQ_u[0][0]                       \n",
      "                                                                 WP_v[0][0]                       \n",
      "                                                                 v[0][0]                          \n",
      "                                                                 W_g1[0][0]                       \n",
      "                                                                 vv[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 300, 150)     0           rnn_41[0][0]                     \n",
      "                                                                 rnn_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 300, 150)     6054150     Passage[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "WQ_v (SharedWeightLayer)        (150, 75)            11250                                        \n",
      "__________________________________________________________________________________________________\n",
      "VQ_r (SharedWeightLayer)        (75, 75)             5625                                         \n",
      "__________________________________________________________________________________________________\n",
      "gru_63 (GRU)                    (None, 300, 75)      50850       concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "W_g2 (SharedWeightLayer)        (75, 75)             5625                                         \n",
      "__________________________________________________________________________________________________\n",
      "WPP_v (SharedWeightLayer)       (75, 75)             5625                                         \n",
      "__________________________________________________________________________________________________\n",
      "vv2 (SharedWeightLayer)         (150, 75)            11250                                        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 150)          0           embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "question_pooling_9 (QuestionPoo (None, 150)          0           bidirectional_54[0][0]           \n",
      "                                                                 WQ_u[0][0]                       \n",
      "                                                                 WQ_v[0][0]                       \n",
      "                                                                 v[0][0]                          \n",
      "                                                                 VQ_r[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "rnn_43 (RNN)                    (None, 300, 75)      67950       gru_63[0][0]                     \n",
      "                                                                 gru_63[0][0]                     \n",
      "                                                                 W_g2[0][0]                       \n",
      "                                                                 WPP_v[0][0]                      \n",
      "                                                                 WP_v[0][0]                       \n",
      "                                                                 v[0][0]                          \n",
      "                                                                 vv2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "rnn_44 (RNN)                    (None, 300, 75)      67950       gru_63[0][0]                     \n",
      "                                                                 gru_63[0][0]                     \n",
      "                                                                 W_g2[0][0]                       \n",
      "                                                                 WPP_v[0][0]                      \n",
      "                                                                 WP_v[0][0]                       \n",
      "                                                                 v[0][0]                          \n",
      "                                                                 vv2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fake_input (RepeatVector)       (None, 2, 150)       0           global_max_pooling1d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "rQ (Dropout)                    (None, 150)          0           question_pooling_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 300, 150)     0           rnn_43[0][0]                     \n",
      "                                                                 rnn_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "WP_h (SharedWeightLayer)        (150, 75)            11250                                        \n",
      "__________________________________________________________________________________________________\n",
      "Wa_h (SharedWeightLayer)        (150, 75)            11250                                        \n",
      "__________________________________________________________________________________________________\n",
      "rnn_45 (RNN)                    (None, 2, 150)       135450      fake_input[0][0]                 \n",
      "                                                                 rQ[0][0]                         \n",
      "                                                                 concatenate_18[0][0]             \n",
      "                                                                 WP_h[0][0]                       \n",
      "                                                                 Wa_h[0][0]                       \n",
      "                                                                 v[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "answer_start (Slice)            (None, 150)          0           rnn_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "answer_end (Slice)              (None, 150)          0           rnn_45[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 19,421,175\n",
      "Trainable params: 1,258,725\n",
      "Non-trainable params: 18,162,450\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Predicting...Done\n"
     ]
    }
   ],
   "source": [
    "print('Preparing model...')\n",
    "model = RNet(vocab_size=len(embeddings_matrix), vocab_init=embeddings_matrix, hdim=75, dropout=0, p_length=300, q_length=20, char_level_embeddings=False)\n",
    "\n",
    "model.load_weights('./models_fasttext/12-t5.969982604980469-v6.554200880468493.model')\n",
    "\n",
    "inputs = model.inputs\n",
    "outputs = [Argmax()(output) for output in model.outputs]\n",
    "#outputs = [output for output in model.outputs]\n",
    "\n",
    "predicting_model = Model(inputs, outputs)\n",
    "\n",
    "#predicting_model.compile(optimizer='Adadelta', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "print('Predicting...', end='')\n",
    "#print(model.evaluate([trainP, trainQ], [train_start, train_end]))\n",
    "#print(predicting_model.evaluate([valP, valQ], [val_start, val_end]))\n",
    "start, end = predicting_model.predict([encode_context, encode_ques])\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "南宋建炎二年，為防禦金兵南下，東京守將杜充在滑州人為決開黃河堤防，造成黃河改道，向東南分由泗水和濟水入海。黃河至此由北入渤海改而南入黃海。直到1855年，黃河主要是在南面擺動，雖然時有北沖，但均被人力強行逼堵南流。\n",
      "最近的一次黃河大改道是在清咸豐年間。咸豐五年六月十九日，黃河在河南蘭考北岸的銅瓦廂決口，改東北走向，在山東境內借濟水入渤海。\n",
      "1938年6月9日，國軍為阻擋日軍，破壞鄭州黃河南岸花園口大堤，全河又向南流，沿賈魯河、潁河、渦河入淮河。直到1947年堵復花園口後，黃河才回歸北道。\n",
      "據歷史記載，在1946年前的2540年間，黃河受到近1593次氾濫威脅，而因氾濫令河道大改道共26次。\n",
      "['自', '何時', '開始', '黃河', '由北入', '渤海', '改而', '由', '南入', '黃海']\n",
      "======================================\n",
      "['1855', '年']\n",
      "1855年\n"
     ]
    }
   ],
   "source": [
    "num = 8\n",
    "print(all_context[num])\n",
    "print(ques[num])\n",
    "print('======================================')\n",
    "print(test_context[num][start[num]: end[num] + 1])\n",
    "start_ = all_context[num].find(test_context[num][start[num]])\n",
    "len_ = len(test_context[num][start[num]]) + len(test_context[num][end[num]])\n",
    "print(all_context[num][start_ : start_+len_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for index, article in enumerate(all_context):\n",
    "    start_ = article.find(test_context[index][start[index]])\n",
    "    len_ = len(test_context[index][start[index]]) + len(test_context[index][end[index]])\n",
    "    ans_list = ' '.join([str(i) for i in range(start_, start_ + len_)])\n",
    "    results.append([str(ids[index]), ans_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1741\n"
     ]
    }
   ],
   "source": [
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result.txt', 'w') as f:\n",
    "    f.write('id,answer\\n')\n",
    "    for ii in results:\n",
    "        f.write(ii[0] + ',' + ii[1] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
